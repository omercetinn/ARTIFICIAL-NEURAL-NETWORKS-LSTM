from google.colab import drive
drive.mount('/content/drive')

##library setup
import numpy as np
import pandas as pd
import lightgbm as lgb
import statsmodels.api as sm
import matplotlib.pyplot as plt
import warnings
import seaborn as sns

from sklearn.model_selection import train_test_split,GridSearchCV,cross_val_score,cross_val_predict
from sklearn.metrics import mean_squared_error,r2_score

from scipy import stats
%matplotlib inline
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import Sequential, layers, callbacks
from tensorflow.keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional
from sklearn.preprocessing import MinMaxScaler, StandardScaler

#from sklearn.clu

warnings.filterwarnings('ignore')
pd.set_option('display.width', None)

##read excel file by date
pd.read_excel('/content/drive/MyDrive/Enerji_Tahmin_Verileri/tez_calismasi.xlsx', parse_dates = ['Date'])

##creating a copy file to avoid making changes to the actual data
df=pd.read_excel('/content/drive/MyDrive/Enerji_Tahmin_Verileri/tez_calismasi.xlsx', parse_dates = ['Date']).copy()

#first data views
df.head()

#last 5 data views
df.tail()

df.info() #data all structural information

df.shape #number of columns and rows

df.mean() #gives the average of all variables

df.std() #standard deviation of all data

df.var() #variance of all data

df["EnerjiVerileri"].mean() #gives the average of all energy data

df["EnerjiVerileri"].min()

df["EnerjiVerileri"].max()

df.describe().T #all descriptive statistics

df.isnull().values.any() #Are there any missing observations?

df.dropna().describe().T #descriptive display of all missing data